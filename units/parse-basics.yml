title: Parsing basics
theme: wrangle
needs:
- data-structure-basics
- manip-basics
readings: ~
updated: ~
desc: "\nSo far you've worked with data sets that have been bundled in R packages,
  or have been created with `tibble()` or `tribble()`. Now it's time to learn how
  to read simple flat files from disk. To do this, we'll use functions from [readr](http://readr.tidyverse.org).
  readr is one of the core tidyverse packages, so you won't usually load it explicitly.\n\n```
  r\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────────── tidyverse
  1.2.1 ──\n#> ✔ ggplot2 3.1.0          ✔ purrr   0.3.0     \n#> ✔ tibble  2.0.1.9001
  \    ✔ dplyr   0.8.0.1   \n#> ✔ tidyr   0.8.2          ✔ stringr 1.4.0     \n#>
  ✔ readr   1.3.1          ✔ forcats 0.4.0\n#> ── Conflicts ──────────────────────────
  tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()
  \   masks stats::lag()\n```\n\nDelimited files\n---------------\n\nIn this unit,
  we're going to focus on delimited files. Delimited files have a **delimiter** between
  each value. Two types make up the majority of delimited files that you'll see in
  the wild: csv (comma separated) and tsv (tab separated). We'll focus on csv files,
  but everything you'll learn applies equally to tsvs, replacing commas with tabs.\n\nA
  typical csv file looks something like this:\n\n    Sepal.Length,Sepal.Width,Petal.Length,Petal.Width,Species\n
  \   5.1,3.5,1.4,0.2,setosa\n    4.9,3,1.4,0.2,setosa\n    4.7,3.2,1.3,0.2,setosa\n
  \   4.6,3.1,1.5,0.2,setosa\n    5,3.6,1.4,0.2,setosa\n    5.4,3.9,1.7,0.4,setosa\n
  \   4.6,3.4,1.4,0.3,setosa\n    5,3.4,1.5,0.2,setosa\n\nNote that:\n\n-   The first
  line gives the column names\n-   Each subsequent line is one row of data\n-   Each
  value is separated by a comma (hence the name)\n\nTypically you can recognise a
  csv file by its extension: `.csv`. But beware! Sometimes the extension lies, and
  if you're getting weird errors when reading a file, it's a good idea to peek inside
  the file using `readr::read_lines()` and `writeLines()`, specifying the `n_max`
  argument to just look at the first few lines. (You'll learn more about `writeLines()`
  when we get to strings; for now just remember it's a useful tool for printing lines
  to the screen.)\n\n``` r\n\"data/heights.csv\" %>% \n  read_lines(n_max = 10) %>%\n
  \ writeLines()\n#> \"earn\",\"height\",\"sex\",\"ed\",\"age\",\"race\"\n#> 50000,74.4244387818035,\"male\",16,45,\"white\"\n#>
  60000,65.5375428255647,\"female\",16,58,\"white\"\n#> 30000,63.6291977374349,\"female\",16,29,\"white\"\n#>
  50000,63.1085616752971,\"female\",16,91,\"other\"\n#> 51000,63.4024835710879,\"female\",17,39,\"white\"\n#>
  9000,64.3995075440034,\"female\",15,26,\"white\"\n#> 29000,61.6563258264214,\"female\",12,49,\"white\"\n#>
  32000,72.6985437364783,\"male\",17,46,\"white\"\n#> 2000,72.0394668497611,\"male\",15,21,\"hispanic\"\n```\n\nThis
  file illustrates another feature present in many csv files: some values are surrounded
  by quotes. Confusingly, this isn't a guarantee that the value is a string: some
  csv files also surround numbers in quotes too. As you work with more csv files you'll
  discover there are few hard and fast rules: for pretty much every crazy thing that
  you can imagine, someone has done it in a csv file somewhere.\n\n`read_csv()`\n------------\n\nThe
  workhorse for reading in csv files is called `read_csv()`. You give it a path to
  a csv file and it gives you back a tibble:\n\n``` r\nheights <- read_csv(\"data/heights.csv\")\n#>
  Parsed with column specification:\n#> cols(\n#>   earn = col_double(),\n#>   height
  = col_double(),\n#>   sex = col_character(),\n#>   ed = col_double(),\n#>   age
  = col_double(),\n#>   race = col_character()\n#> )\nheights\n#> # A tibble: 1,192
  x 6\n#>     earn height sex       ed   age race    \n#>    <dbl>  <dbl> <chr>  <dbl>
  <dbl> <chr>   \n#>  1 50000   74.4 male      16    45 white   \n#>  2 60000   65.5
  female    16    58 white   \n#>  3 30000   63.6 female    16    29 white   \n#>
  \ 4 50000   63.1 female    16    91 other   \n#>  5 51000   63.4 female    17    39
  white   \n#>  6  9000   64.4 female    15    26 white   \n#>  7 29000   61.7 female
  \   12    49 white   \n#>  8 32000   72.7 male      17    46 white   \n#>  9  2000
  \  72.0 male      15    21 hispanic\n#> 10 27000   72.2 male      12    26 white
  \  \n#> # … with 1,182 more rows\n```\n\nIf you are very lucky, you can point `read_csv()`
  at a file and it just works. But this is usually the exception, not the rule, and
  often you'll need to tweak some arguments.\n\nThe most important arguments to `read_csv()`
  are:\n\n-   `col_names`: usually `col_names = TRUE` which tells `read_csv()` that
  the first line of the file is the column names. If there aren't any column names
  set `col_names = FALSE` or supply a character vector telling `read_csv()` what they
  should be `col_names = c(\"x\", \"y\", \"z\")`\n\n-   `col_types`: you might have
  noticed that when we called `read_csv()` above it printed out a list of column \"specifications\".
  That describes how readr converts each column into an data structure. readr uses
  some pretty good heuristics to guess the type, but sometimes the heuristics fail
  and you'll need to supply the truth. You'll learn more about that later in the course\n\n-
  \  It's fairly common to encounter csv files that have a bunch of \U0001F4A9 at
  the top. You can use `skip = n` to skip the first n lines, or `comment = \"#\"`
  to ignore all lines that start with `#`.\n\n-   `read_csv()` expects missing values
  to be suppled as `NA`. If your file uses a different convention, use `na = \".\"`
  to override the default.\n\nYou'll get to practice using these arguments in the
  exercises.\n"
