title: Parsing basics
theme: wrangle
needs:
- data-structure-basics
- manip-basics
readings: ~
updated: ~
desc: "\nSo far you’ve worked with data sets that have been bundled in R\npackages,
  or have been created with `tibble()` or `tribble()`. Now it’s\ntime to learn how
  to read simple flat files from disk. To do this, we’ll\nuse functions from [readr](http://readr.tidyverse.org).
  readr is one of\nthe core tidyverse packages, so you won’t usually load it explicitly.\n\n```
  r\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────────────────────────────────────────
  tidyverse 1.2.0.9000 ──\n#> ✔ ggplot2 2.2.1.9000     ✔ purrr   0.2.4     \n#> ✔
  tibble  1.4.1          ✔ dplyr   0.7.4     \n#> ✔ tidyr   0.7.2          ✔ stringr
  1.2.0     \n#> ✔ readr   1.1.1          ✔ forcats 0.2.0\n#> ── Conflicts ─────────────────────────────────────────────────────────────
  tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()
  \   masks stats::lag()\n```\n\n## Delimited files\n\nIn this unit, we’re going to
  focus on delimited files. Delimited files\nhave a **delimiter** between each value.
  Two types make up the majority\nof delimited files that you’ll see in the wild:
  csv (comma separated)\nand tsv (tab separated). We’ll focus on csv files, but everything
  you’ll\nlearn applies equally to tsvs, replacing commas with tabs.\n\nA typical
  csv file looks something like this:\n\n    Sepal.Length,Sepal.Width,Petal.Length,Petal.Width,Species\n
  \   5.1,3.5,1.4,0.2,setosa\n    4.9,3,1.4,0.2,setosa\n    4.7,3.2,1.3,0.2,setosa\n
  \   4.6,3.1,1.5,0.2,setosa\n    5,3.6,1.4,0.2,setosa\n    5.4,3.9,1.7,0.4,setosa\n
  \   4.6,3.4,1.4,0.3,setosa\n    5,3.4,1.5,0.2,setosa\n\nNote that:\n\n  - The first
  line gives the column names\n  - Each subsequent line is one row of data\n  - Each
  value is separated by a comma (hence the name)\n\nTypically you can recognise a
  csv file by its extension: `.csv`. But\nbeware\\! Sometimes the extension lies,
  and if you’re getting weird\nerrors when reading a file, it’s a good idea to peek
  inside the file\nusing `readr::read_lines()` and `writeLines()`, specifying the
  `n_max`\nargument to just look at the first few lines. (You’ll learn more about\n`writeLines()`
  when we get to strings; for now just remember it’s a\nuseful tool for printing lines
  to the screen.)\n\n``` r\n\"heights.csv\" %>% \n  read_lines(n_max = 10) %>%\n  writeLines()\n#>
  \"earn\",\"height\",\"sex\",\"ed\",\"age\",\"race\"\n#> 50000,74.4244387818035,\"male\",16,45,\"white\"\n#>
  60000,65.5375428255647,\"female\",16,58,\"white\"\n#> 30000,63.6291977374349,\"female\",16,29,\"white\"\n#>
  50000,63.1085616752971,\"female\",16,91,\"other\"\n#> 51000,63.4024835710879,\"female\",17,39,\"white\"\n#>
  9000,64.3995075440034,\"female\",15,26,\"white\"\n#> 29000,61.6563258264214,\"female\",12,49,\"white\"\n#>
  32000,72.6985437364783,\"male\",17,46,\"white\"\n#> 2000,72.0394668497611,\"male\",15,21,\"hispanic\"\n```\n\nThis
  file illustrates another feature present in many csv files: some\nvalues are surrounded
  by quotes. Confusingly, this isn’t a guarantee\nthat the value is a string: some
  csv files also surround numbers in\nquotes too. As you work with more csv files
  you’ll discover there are\nfew hard and fast rules: for pretty much every crazy
  thing that you can\nimagine, someone has done it in a csv file somewhere.\n\n##
  `read_csv()`\n\nThe workhorse for reading in csv files is called `read_csv()`. You
  give\nit a path to a csv file and it gives you back a tibble:\n\n``` r\nheights
  <- read_csv(\"heights.csv\")\n#> Parsed with column specification:\n#> cols(\n#>
  \  earn = col_double(),\n#>   height = col_double(),\n#>   sex = col_character(),\n#>
  \  ed = col_integer(),\n#>   age = col_integer(),\n#>   race = col_character()\n#>
  )\nheights\n#> # A tibble: 1,192 x 6\n#>     earn height sex       ed   age race
  \   \n#>    <dbl>  <dbl> <chr>  <int> <int> <chr>   \n#>  1 50000   74.4 male      16
  \   45 white   \n#>  2 60000   65.5 female    16    58 white   \n#>  3 30000   63.6
  female    16    29 white   \n#>  4 50000   63.1 female    16    91 other   \n#>
  \ 5 51000   63.4 female    17    39 white   \n#>  6  9000   64.4 female    15    26
  white   \n#>  7 29000   61.7 female    12    49 white   \n#>  8 32000   72.7 male
  \     17    46 white   \n#>  9  2000   72.0 male      15    21 hispanic\n#> 10 27000
  \  72.2 male      12    26 white   \n#> # ... with 1,182 more rows\n```\n\nIf you
  are very lucky, you can point `read_csv()` at a file and it just\nworks. But this
  is usually the exception, not the rule, and often you’ll\nneed to tweak some arguments.\n\nThe
  most important arguments to `read_csv()` are:\n\n  - `col_names`: usually `col_names
  = TRUE` which tells `read_csv()`\n    that the first line of the file is the column
  names. If there aren’t\n    any column names set `col_names = FALSE` or supply a
  character\n    vector telling `read_csv()` what they should be `col_names = c(\"x\",\n
  \   \"y\", \"z\")`\n\n  - `col_types`: you might have noticed that when we called
  `read_csv()`\n    above it printed out a list of column “specifications”. That\n
  \   describes how readr converts each column into an data structure.\n    readr
  uses some pretty good heuristics to guess the type, but\n    sometimes the heuristics
  fail and you’ll need to supply the truth.\n    You’ll learn more about that later
  in the course\n\n  - It’s fairly common to encounter csv files that have a bunch
  of \U0001F4A9 at\n    the top. You can use `skip = n` to skip the first n lines,
  or\n    `comment = \"#\"` to ignore all lines that start with `#`.\n\n  - `read_csv()`
  expects missing values to be suppled as `NA`. If your\n    file uses a different
  convention, use `na = \".\"` to override the\n    default.\n\nYou’ll get to practice
  using these arguments in the exercises.\n"
