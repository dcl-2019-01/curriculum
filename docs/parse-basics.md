---
title: Parsing basics
---

<!-- Generated automatically from parse-basics.yml. Do not edit by hand -->

# Parsing basics <small class='wrangle'>[wrangle]</small>
<small>(Builds on: [Data structure basics](data-structure-basics.md), [Manipulation basics](manip-basics.md))</small>  
<small>(Leads to: [Exporting data](export.md), [Google sheets](googlesheets.md), [Parsing details](parse-details.md))</small>


So far you‚Äôve worked with data sets that have been bundled in R
packages, or have been created with `tibble()` or `tribble()`. Now it‚Äôs
time to learn how to read simple flat files from disk. To do this, we‚Äôll
use functions from [readr](http://readr.tidyverse.org). readr is one of
the core tidyverse packages, so you won‚Äôt usually load it explicitly.

``` r
library(tidyverse)
#> ‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.2.0.9000 ‚îÄ‚îÄ
#> ‚úî ggplot2 2.2.1.9000     ‚úî purrr   0.2.4     
#> ‚úî tibble  1.4.1          ‚úî dplyr   0.7.4     
#> ‚úî tidyr   0.7.2          ‚úî stringr 1.2.0     
#> ‚úî readr   1.1.1          ‚úî forcats 0.2.0
#> ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ
#> ‚úñ dplyr::filter() masks stats::filter()
#> ‚úñ dplyr::lag()    masks stats::lag()
```

## Delimited files

In this unit, we‚Äôre going to focus on delimited files. Delimited files
have a **delimiter** between each value. Two types make up the majority
of delimited files that you‚Äôll see in the wild: csv (comma separated)
and tsv (tab separated). We‚Äôll focus on csv files, but everything you‚Äôll
learn applies equally to tsvs, replacing commas with tabs.

A typical csv file looks something like this:

    Sepal.Length,Sepal.Width,Petal.Length,Petal.Width,Species
    5.1,3.5,1.4,0.2,setosa
    4.9,3,1.4,0.2,setosa
    4.7,3.2,1.3,0.2,setosa
    4.6,3.1,1.5,0.2,setosa
    5,3.6,1.4,0.2,setosa
    5.4,3.9,1.7,0.4,setosa
    4.6,3.4,1.4,0.3,setosa
    5,3.4,1.5,0.2,setosa

Note that:

  - The first line gives the column names
  - Each subsequent line is one row of data
  - Each value is separated by a comma (hence the name)

Typically you can recognise a csv file by its extension: `.csv`. But
beware\! Sometimes the extension lies, and if you‚Äôre getting weird
errors when reading a file, it‚Äôs a good idea to peek inside the file
using `readr::read_lines()` and `writeLines()`, specifying the `n_max`
argument to just look at the first few lines. (You‚Äôll learn more about
`writeLines()` when we get to strings; for now just remember it‚Äôs a
useful tool for printing lines to the screen.)

``` r
"heights.csv" %>% 
  read_lines(n_max = 10) %>%
  writeLines()
#> "earn","height","sex","ed","age","race"
#> 50000,74.4244387818035,"male",16,45,"white"
#> 60000,65.5375428255647,"female",16,58,"white"
#> 30000,63.6291977374349,"female",16,29,"white"
#> 50000,63.1085616752971,"female",16,91,"other"
#> 51000,63.4024835710879,"female",17,39,"white"
#> 9000,64.3995075440034,"female",15,26,"white"
#> 29000,61.6563258264214,"female",12,49,"white"
#> 32000,72.6985437364783,"male",17,46,"white"
#> 2000,72.0394668497611,"male",15,21,"hispanic"
```

This file illustrates another feature present in many csv files: some
values are surrounded by quotes. Confusingly, this isn‚Äôt a guarantee
that the value is a string: some csv files also surround numbers in
quotes too. As you work with more csv files you‚Äôll discover there are
few hard and fast rules: for pretty much every crazy thing that you can
imagine, someone has done it in a csv file somewhere.

## `read_csv()`

The workhorse for reading in csv files is called `read_csv()`. You give
it a path to a csv file and it gives you back a tibble:

``` r
heights <- read_csv("heights.csv")
#> Parsed with column specification:
#> cols(
#>   earn = col_double(),
#>   height = col_double(),
#>   sex = col_character(),
#>   ed = col_integer(),
#>   age = col_integer(),
#>   race = col_character()
#> )
heights
#> # A tibble: 1,192 x 6
#>     earn height sex       ed   age race    
#>    <dbl>  <dbl> <chr>  <int> <int> <chr>   
#>  1 50000   74.4 male      16    45 white   
#>  2 60000   65.5 female    16    58 white   
#>  3 30000   63.6 female    16    29 white   
#>  4 50000   63.1 female    16    91 other   
#>  5 51000   63.4 female    17    39 white   
#>  6  9000   64.4 female    15    26 white   
#>  7 29000   61.7 female    12    49 white   
#>  8 32000   72.7 male      17    46 white   
#>  9  2000   72.0 male      15    21 hispanic
#> 10 27000   72.2 male      12    26 white   
#> # ... with 1,182 more rows
```

If you are very lucky, you can point `read_csv()` at a file and it just
works. But this is usually the exception, not the rule, and often you‚Äôll
need to tweak some arguments.

The most important arguments to `read_csv()` are:

  - `col_names`: usually `col_names = TRUE` which tells `read_csv()`
    that the first line of the file is the column names. If there aren‚Äôt
    any column names set `col_names = FALSE` or supply a character
    vector telling `read_csv()` what they should be `col_names = c("x",
    "y", "z")`

  - `col_types`: you might have noticed that when we called `read_csv()`
    above it printed out a list of column ‚Äúspecifications‚Äù. That
    describes how readr converts each column into an data structure.
    readr uses some pretty good heuristics to guess the type, but
    sometimes the heuristics fail and you‚Äôll need to supply the truth.
    You‚Äôll learn more about that later in the course

  - It‚Äôs fairly common to encounter csv files that have a bunch of üí© at
    the top. You can use `skip = n` to skip the first n lines, or
    `comment = "#"` to ignore all lines that start with `#`.

  - `read_csv()` expects missing values to be suppled as `NA`. If your
    file uses a different convention, use `na = "."` to override the
    default.

You‚Äôll get to practice using these arguments in the exercises.

